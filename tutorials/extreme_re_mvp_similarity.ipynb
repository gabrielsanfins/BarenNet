{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extreme $Re$ Newtonian Similarity\n",
    "\n",
    "As usual, we will begin by importing the necessary python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from barennet import SimilarityModel\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Uncomment the line below if if you have tensorflow issues regarding your GPU:\n",
    "\n",
    "# tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will find the incomplete similarity exponents for the extreme $Re$ newtonian \n",
    "mean velocity profile in wall coordinates. We know that the dimensionless quantities\n",
    "involved are $(u^+, y^+, Re_\\tau)$ and, although we don't know the relation between\n",
    "them, we have reason to believe that they have the following similarity relation:\n",
    "\n",
    "$$ u^+ = Re_\\tau^{1/12} \\Phi^{(1)} \\left( \\frac{y^+}{Re_\\tau} \\right)$$\n",
    "\n",
    "We provide a data file with experimental MVP data by McKeon et. al. collected at\n",
    "the Princeton Superpipe facility. We will use Reynolds numbers in the range \n",
    "$2.3 \\times 10^6 < Re < 1.3 \\times 10^7$. The MDDP construction of the three \n",
    "dimensionless quantities is also provided in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../Data/extreme_re_MVP_data.xlsx\"\n",
    "dimensionally_independent_parameters = [\"mu\", \"rho\", \"delta\"]\n",
    "dimensionally_dependent_parameters = [\"y\", \"- dp/dz\"]\n",
    "dimensional_qoi = \"u\"\n",
    "non_dimensional_parameters = [\"y+\", \"Re_tau\"]\n",
    "non_dimensional_qoi = \"u+\"\n",
    "non_dimensional_params_construction = { \n",
    "    \"y+\": {\"y\": 1.0, \"- dp/dz\": 0.5, \"mu\": -1, \"rho\": 0.5, \"delta\": 0.5},\n",
    "    \"Re_tau\": {\"y\": 0.0, \"- dp/dz\": 0.5, \"mu\": -1, \"rho\": 0.5, \"delta\": 1.5}, \n",
    "}\n",
    "non_dimensional_qoi_construction = {\n",
    "    \"u+\": {\"u\": 1, \"y\": 0.0, \"- dp/dz\": -0.5, \"mu\": 0.0, \"rho\": 0.5, \"delta\": -0.5}\n",
    "}\n",
    "non_similar_params = [\"y+\"]\n",
    "similar_params = [\"Re_tau\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_model = SimilarityModel(\n",
    "    data_path=data_path,\n",
    "    dimensionally_independent_params=dimensionally_independent_parameters,\n",
    "    dimensionally_dependent_params=dimensionally_dependent_parameters,\n",
    "    dimensional_qoi=dimensional_qoi,\n",
    "    non_dimensional_params=non_dimensional_parameters,\n",
    "    non_dimensional_qoi=non_dimensional_qoi,\n",
    "    non_dimensional_params_construction=non_dimensional_params_construction,\n",
    "    non_dimesional_qoi_construction=non_dimensional_qoi_construction,\n",
    "    non_similar_params=non_similar_params,\n",
    "    similar_params=similar_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buckingham's Similarity Group\n",
    "\n",
    "As soon as the dimensionless construction is provided and we create an instance \n",
    "of the SimilarityModel class, the Buckingham's similarity group can be calculated\n",
    "by solving a linear system (chapter 5 of the thesis).\n",
    "It shoud read:\n",
    "\\begin{align*}\n",
    "    &\\mu^* = A_1 \\mu, \\ \\ \\ \\rho^* = A_2 \\rho, \\ \\ \\ \\delta^* = A_3 \\delta \\\\ & \\\\\n",
    "    & y^* = A_3 y \\\\ & \\\\\n",
    "    & \\left( \\frac{dp}{dz} \\right)^* = \\frac{A_1^2}{A_2 A_3^3} \\left( \\frac{dp}{dz} \\right) \\\\ & \\\\\n",
    "    &U^* = \\frac{A_1}{A_2 A_3} U\n",
    "\\end{align*}\n",
    "\n",
    "And, as you can see, this is exactly the output of the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_model.print_buckingham_similarity_group()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the find_incomplete_similarity method in order to use the BarenNet to find proper incomplete similarity exponents, as well as estimating the function $\\Phi^{(1)}$ with a Deep Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_model.find_incomplete_similarity(n_tries=5, n_epochs=10000, tol=5e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training has been performed, we can check the exponents found by the BarenNet by printing the dictionary used to store them in our class. \n",
    "\n",
    "$\\cdot$ The entry dict[\"y+\"][\"Re_tau\"] refers to the exponent of $Re_\\tau$ when it is multiplied by $y^+$ i.e. $\\xi_2^{(1)}$;\n",
    "\n",
    "$\\cdot$ As one should expect, the entry dict[\"u+\"][\"Re_tau\"] refers to the exponent of $Re_\\tau$ when it is multiplied by $u^+$ i.e. $\\xi_1$.\n",
    "\n",
    "By looking at the incomplete similarity theoretical equation above, we come to the conclusion that $\\xi_1 \\approx - 1/12$ and  $\\xi_2^{(1)} \\approx -1$. Let's see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(similarity_model.incomplete_similarity_exponents_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that incomplete similarity has been found, our package has already automatically calculated the renormalization group from the exponents found. Much like Buckingham's similarity group, we can print it with the following method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_model.print_renormalization_group()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will do plot some data points in original coordinates and, afterwards, plot the same points in the renormalized dimensionless coordinates. A data collapse is expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "plt.rc('mathtext', fontset=\"cm\")\n",
    "import matplotlib.ticker as mtick\n",
    "from matplotlib import cm # Colormaps\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "\n",
    "from tutorial_utils.plotting_methods import (plot_extreme_re_flow,\n",
    "                                             plot_extreme_re_flow_renormalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_extreme_re_flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_extreme_re_flow_renormalized(similarity_model.incomplete_similarity_exponents_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "barennet_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
