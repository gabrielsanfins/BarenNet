{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-12 10:45:37.802187: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-12 10:45:37.802204: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "  sys.path.append(module_path)\n",
    "\n",
    "from utils.utils import Create_Similarity_Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we will create our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nonsimilar = 1\n",
    "n_similar = 1\n",
    "\n",
    "### We will look for similarity in the last n_similar parameters of the inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the MVP data for high enough Re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSB2M300k_M=pd.read_csv(\"../../Data/McKeon Data/turb2/Re2300000.txt\",  sep=\"\\t\", header=None, names = [\"datapoint\", \"y/R\", \"y+\", \"U+\", \"(U+-Ucl+)\"])\n",
    "dfSB3M_M=pd.read_csv(\"../../Data/McKeon Data/turb2/Re3000000.txt\", sep=\"\\t\", header=None, names = [\"datapoint\", \"y/R\", \"y+\", \"U+\", \"(U+-Ucl+)\"])\n",
    "dfSB4M_M=pd.read_csv(\"../../Data/McKeon Data/turb2/Re4000000.txt\", sep=\"\\t\", header=None, names = [\"datapoint\", \"y/R\", \"y+\", \"U+\", \"(U+-Ucl+)\"])\n",
    "dfSB6M_M=pd.read_csv(\"../../Data/McKeon Data/turb2/Re6000000.txt\", sep=\"\\t\", header=None, names = [\"datapoint\", \"y/R\", \"y+\", \"U+\", \"(U+-Ucl+)\"])\n",
    "dfSB7M_M=pd.read_csv(\"../../Data/McKeon Data/turb2/Re7000000.txt\", sep=\"\\t\", header=None, names = [\"datapoint\", \"y/R\", \"y+\", \"U+\", \"(U+-Ucl+)\"])\n",
    "dfSB10M_M=pd.read_csv(\"../../Data/McKeon Data/turb2/Re10000000.txt\", sep=\"\\t\", header=None, names = [\"datapoint\", \"y/R\", \"y+\", \"U+\", \"(U+-Ucl+)\"])\n",
    "dfSB13M_M=pd.read_csv(\"../../Data/McKeon Data/turb2/Re13000000.txt\", sep=\"\\t\", header=None, names = [\"datapoint\", \"y/R\", \"y+\", \"U+\", \"(U+-Ucl+)\"])\n",
    "\n",
    "dfs = [dfSB2M300k_M, dfSB3M_M, dfSB4M_M, dfSB6M_M, dfSB7M_M, dfSB10M_M, dfSB13M_M]\n",
    "Re_tau = []\n",
    "Y_ = []\n",
    "U_ = []\n",
    "possible_re_tau = [4.229500e+004, 5.453000e+004, 7.647800e+004, 1.022e+005, 1.279200e+005, 1.657e+005, 2.169800e+005]\n",
    "dic_x = {}\n",
    "dic_y = {}\n",
    "\n",
    "for i in range(len(possible_re_tau)):\n",
    "    possible_y = dfs[i][\"y+\"].values\n",
    "    possible_u = dfs[i][\"U+\"].values\n",
    "    for j in range(38, len(possible_y)-1):\n",
    "        Y_.append(possible_y[j])\n",
    "        U_.append(possible_u[j])\n",
    "        Re_tau.append(possible_re_tau[i])\n",
    "\n",
    "c = list(zip(Y_, Re_tau, U_))\n",
    "random.shuffle(c)\n",
    "Y_, Re_tau, U_ = zip(*c)\n",
    "\n",
    "Y_ = np.log(Y_)\n",
    "Re_tau = np.log(Re_tau)\n",
    "\n",
    "dic_x['y+'] = Y_\n",
    "dic_x['re_tau'] = Re_tau\n",
    "dic_y['u+'] = np.array(U_)\n",
    "\n",
    "nonsimilar_keys = ['y+']\n",
    "\n",
    "xtrain = pd.DataFrame.from_dict(dic_x).values\n",
    "ytrain = pd.DataFrame.from_dict(dic_y).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-12 10:45:45.656306: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-12 10:45:45.656648: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-12 10:45:45.656691: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-07-12 10:45:45.656729: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-07-12 10:45:45.656768: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-07-12 10:45:45.656869: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-07-12 10:45:45.656910: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-07-12 10:45:45.656947: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-07-12 10:45:45.656990: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-07-12 10:45:45.656996: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-07-12 10:45:45.657193: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "991.7304077148438\n",
      "991.7304077148438\n",
      "991.7304077148438\n",
      "0.009624634869396687\n",
      "991.7304077148438\n",
      "0.01273947861045599\n",
      "991.7304077148438\n",
      "177.64552307128906\n",
      "991.7304077148438\n",
      "991.7304077148438\n",
      "nan\n",
      "991.7304077148438\n",
      "991.7304077148438\n",
      "991.7304077148438\n",
      "991.7304077148438\n",
      "991.7304077148438\n",
      "0.013766570948064327\n",
      "991.7304077148438\n",
      "991.7304077148438\n",
      "178.5313720703125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcbd86b7040>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = 'mean_squared_error'\n",
    "optimizer = 'adam'\n",
    "best_loss = 50.0\n",
    "n_fits = 20                       # Number of model fits we will try to perform\n",
    "n_epochs_initial = 10000          # Number of epochs we will train inside the loop\n",
    "n_epochs_final = 10000          # Number of epochs we will train after convergence is established\n",
    "\n",
    "for i in range(n_fits):\n",
    "    model = Create_Similarity_Model(n_nonsimilar = n_nonsimilar, n_similar = n_similar)\n",
    "    model.compile(loss = loss, optimizer = optimizer)\n",
    "    model.fit(xtrain, ytrain, epochs = n_epochs_initial, verbose = 0)\n",
    "    current_loss = model.evaluate(xtrain, ytrain, verbose = 0)\n",
    "    print(current_loss)\n",
    "    if current_loss < best_loss:\n",
    "        best_model = model\n",
    "        best_loss = current_loss\n",
    "\n",
    "best_model.fit(xtrain, ytrain, epochs = n_epochs_final, verbose = 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01670107990503311"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(xtrain, ytrain, epochs = 10000, verbose = 0)\n",
    "best_model.evaluate(xtrain, ytrain, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exponents multiplicating inside the function for y+: [-0.9917527]\n",
      "Exponents multiplicating outside the function: [0.07298566]\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_nonsimilar):\n",
    "    similarity_exponents = best_model.get_layer('similarity_layer_' + str(i+1)).weights[0][0].numpy()\n",
    "    print('Exponents multiplicating inside the function for ' + nonsimilar_keys[i] + ': ' + str(similarity_exponents))\n",
    "\n",
    "multiplication_exponents = best_model.get_layer('multiplication_layer').weights[0][0].numpy()\n",
    "print('Exponents multiplicating outside the function: ' + str(multiplication_exponents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
